{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries and Modules</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy\n",
    "# !pip install scikit-learn==0.22.1 --user\n",
    "# !pip install imblearn --user\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import datetime\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Datasets\n",
    "train = pd.read_csv('../../data/weka_processed/train_pro.csv')\n",
    "test = pd.read_csv('../../data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Intuition on the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189123628</td>\n",
       "      <td>10.5</td>\n",
       "      <td>834</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>'11/1/2019 0:20'</td>\n",
       "      <td>'11/1/2019 0:34'</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189125358</td>\n",
       "      <td>10.5</td>\n",
       "      <td>791</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>'11/1/2019 0:56'</td>\n",
       "      <td>'11/1/2019 1:09'</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189125719</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1087</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>'11/1/2019 1:08'</td>\n",
       "      <td>'11/1/2019 1:26'</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189127273</td>\n",
       "      <td>10.5</td>\n",
       "      <td>598</td>\n",
       "      <td>271</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68</td>\n",
       "      <td>'11/1/2019 2:27'</td>\n",
       "      <td>'11/1/2019 2:37'</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189128020</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>'11/1/2019 3:34'</td>\n",
       "      <td>'11/1/2019 3:51'</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid additional_fare duration meter_waiting meter_waiting_fare  \\\n",
       "0  189123628            10.5      834            56                  0   \n",
       "1  189125358            10.5      791            47                  0   \n",
       "2  189125719            10.5     1087            80                  0   \n",
       "3  189127273            10.5      598           271            15.6638   \n",
       "4  189128020               ?        ?             ?                  ?   \n",
       "\n",
       "  meter_waiting_till_pickup       pickup_time         drop_time  pick_lat  \\\n",
       "0                        64  '11/1/2019 0:20'  '11/1/2019 0:34'   6.86252   \n",
       "1                       134  '11/1/2019 0:56'  '11/1/2019 1:09'   6.88589   \n",
       "2                        61  '11/1/2019 1:08'  '11/1/2019 1:26'   6.90839   \n",
       "3                        68  '11/1/2019 2:27'  '11/1/2019 2:37'   6.92570   \n",
       "4                         ?  '11/1/2019 3:34'  '11/1/2019 3:51'   6.87441   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon    fare    label  \n",
       "0   79.8993   6.90330   79.8783  270.32  correct  \n",
       "1   79.8984   6.91373   79.8923  197.85  correct  \n",
       "2   79.8651   6.93669   79.9146  301.64  correct  \n",
       "3   79.8895   6.92748   79.8971    82.3  correct  \n",
       "4   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213284604</td>\n",
       "      <td>10.5</td>\n",
       "      <td>924</td>\n",
       "      <td>42</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>148</td>\n",
       "      <td>2/1/2020 0:38</td>\n",
       "      <td>2/1/2020 0:53</td>\n",
       "      <td>6.83454</td>\n",
       "      <td>79.8750</td>\n",
       "      <td>6.77490</td>\n",
       "      <td>79.8840</td>\n",
       "      <td>289.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213286352</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4249</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>91</td>\n",
       "      <td>2/1/2020 1:02</td>\n",
       "      <td>2/1/2020 2:13</td>\n",
       "      <td>6.91168</td>\n",
       "      <td>79.8723</td>\n",
       "      <td>6.55091</td>\n",
       "      <td>79.9706</td>\n",
       "      <td>1912.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>213293973</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1552</td>\n",
       "      <td>255</td>\n",
       "      <td>2.6588</td>\n",
       "      <td>23</td>\n",
       "      <td>2/1/2020 5:02</td>\n",
       "      <td>2/1/2020 5:28</td>\n",
       "      <td>6.92145</td>\n",
       "      <td>79.8478</td>\n",
       "      <td>6.90539</td>\n",
       "      <td>79.8989</td>\n",
       "      <td>394.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213294622</td>\n",
       "      <td>10.5</td>\n",
       "      <td>462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>2/1/2020 5:30</td>\n",
       "      <td>2/1/2020 5:38</td>\n",
       "      <td>6.77433</td>\n",
       "      <td>79.9416</td>\n",
       "      <td>6.80401</td>\n",
       "      <td>79.9407</td>\n",
       "      <td>154.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213298687</td>\n",
       "      <td>10.5</td>\n",
       "      <td>814</td>\n",
       "      <td>392</td>\n",
       "      <td>12.3692</td>\n",
       "      <td>69</td>\n",
       "      <td>2/1/2020 7:00</td>\n",
       "      <td>2/1/2020 7:14</td>\n",
       "      <td>6.97968</td>\n",
       "      <td>79.9130</td>\n",
       "      <td>6.98875</td>\n",
       "      <td>79.8914</td>\n",
       "      <td>147.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "0  213284604             10.5       924             42              2.4486   \n",
       "1  213286352             10.5      4249             20              0.0000   \n",
       "2  213293973             10.5      1552            255              2.6588   \n",
       "3  213294622             10.5       462             16              0.0000   \n",
       "4  213298687             10.5       814            392             12.3692   \n",
       "\n",
       "   meter_waiting_till_pickup    pickup_time      drop_time  pick_lat  \\\n",
       "0                        148  2/1/2020 0:38  2/1/2020 0:53   6.83454   \n",
       "1                         91  2/1/2020 1:02  2/1/2020 2:13   6.91168   \n",
       "2                         23  2/1/2020 5:02  2/1/2020 5:28   6.92145   \n",
       "3                        198  2/1/2020 5:30  2/1/2020 5:38   6.77433   \n",
       "4                         69  2/1/2020 7:00  2/1/2020 7:14   6.97968   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon     fare  \n",
       "0   79.8750   6.77490   79.8840   289.27  \n",
       "1   79.8723   6.55091   79.9706  1912.70  \n",
       "2   79.8478   6.90539   79.8989   394.00  \n",
       "3   79.9416   6.80401   79.9407   154.32  \n",
       "4   79.9130   6.98875   79.8914   147.47  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15327 entries, 0 to 15326\n",
      "Data columns (total 14 columns):\n",
      "tripid                       15327 non-null int64\n",
      "additional_fare              15327 non-null object\n",
      "duration                     15327 non-null object\n",
      "meter_waiting                15327 non-null object\n",
      "meter_waiting_fare           15327 non-null object\n",
      "meter_waiting_till_pickup    15327 non-null object\n",
      "pickup_time                  15327 non-null object\n",
      "drop_time                    15327 non-null object\n",
      "pick_lat                     15327 non-null float64\n",
      "pick_lon                     15327 non-null float64\n",
      "drop_lat                     15327 non-null float64\n",
      "drop_lon                     15327 non-null float64\n",
      "fare                         15327 non-null object\n",
      "label                        15327 non-null object\n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15327, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8576 entries, 0 to 8575\n",
      "Data columns (total 13 columns):\n",
      "tripid                       8576 non-null int64\n",
      "additional_fare              8576 non-null float64\n",
      "duration                     8576 non-null int64\n",
      "meter_waiting                8576 non-null int64\n",
      "meter_waiting_fare           8576 non-null float64\n",
      "meter_waiting_till_pickup    8576 non-null int64\n",
      "pickup_time                  8576 non-null object\n",
      "drop_time                    8576 non-null object\n",
      "pick_lat                     8576 non-null float64\n",
      "pick_lon                     8576 non-null float64\n",
      "drop_lat                     8576 non-null float64\n",
      "drop_lon                     8576 non-null float64\n",
      "fare                         8576 non-null float64\n",
      "dtypes: float64(7), int64(4), object(2)\n",
      "memory usage: 871.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning weka added unnecessary values\n",
    "\n",
    "train = train.replace({'?': np.nan})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting label values into 0,1 instead of correct, incorrect\n",
    "\n",
    "train.label = train.label.map(dict(correct=1, incorrect=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                         0\n",
       "additional_fare              196\n",
       "duration                     196\n",
       "meter_waiting                196\n",
       "meter_waiting_fare           196\n",
       "meter_waiting_till_pickup    196\n",
       "pickup_time                    0\n",
       "drop_time                      0\n",
       "pick_lat                       0\n",
       "pick_lon                       0\n",
       "drop_lat                       0\n",
       "drop_lon                       0\n",
       "fare                         133\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check for missing values in the dataset\n",
    "\n",
    "# train.isna().head()\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill missing values by mean of the column\n",
    "\n",
    "# train.fillna(train.mean(), inplace=True)\n",
    "\n",
    "# imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "# imputer.fit(train.iloc[:,[1,2,3,4,5,12]])\n",
    "# train.iloc[:,[1,2,3,4,5,12]] = imputer.transform(train.iloc[:,[1,2,3,4,5,12]])\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "train.iloc[:,[1,2,3,4,5,12]] = imputer.fit_transform(train.iloc[:,[1,2,3,4,5,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "label                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join train and test datasets in order to obtain the same number of features during categorical conversion\n",
    "train_len = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Advanced Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new feature columns\n",
    "trip_fare = []\n",
    "trip_duration = []\n",
    "trip_distance = []\n",
    "\n",
    "distance_to_duration = []\n",
    "fare_to_duration = []\n",
    "fare_to_distance = []\n",
    "waiting_fare_to_waiting_duration = []\n",
    "\n",
    "duration_from_time = []\n",
    "duration_error = []\n",
    "\n",
    "## j48 rules\n",
    "duration_bucket = []    ## 50\n",
    "fare_bucket = []        ## 50\n",
    "\n",
    "## dataset inspection rules\n",
    "fare_waiting_gap = []\n",
    "additional_fare_greater_than_250 = []\n",
    "is_duration_zero = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each row in the dataset\n",
    "for row in dataset.itertuples():\n",
    "    fare = float(row.fare)\n",
    "    additional_fare = float(row.additional_fare)\n",
    "    meter_waiting_fare = float(row.meter_waiting_fare)\n",
    "    \n",
    "    meter_waiting = row.meter_waiting\n",
    "    meter_waiting_till_pickup = row.meter_waiting_till_pickup\n",
    "    duration = row.duration\n",
    "    \n",
    "    pick_lat = row.pick_lat\n",
    "    pick_lon = row.pick_lon\n",
    "    drop_lat = row.drop_lat\n",
    "    drop_lon = row.drop_lon\n",
    "    \n",
    "    pickup_time = row.pickup_time.replace('\\'', '')\n",
    "    drop_time = row.drop_time.replace('\\'', '')\n",
    "    pickup_time = pickup_time.split('/')\n",
    "    drop_time = drop_time.split('/')\n",
    "    \n",
    "    # fare bucket\n",
    "    fare_bucket.append(int(math.ceil(fare / 50)))\n",
    "    \n",
    "    # total fare for the trip\n",
    "    cur_trip_fare = fare - (additional_fare + meter_waiting_fare)\n",
    "    trip_fare.append(cur_trip_fare)\n",
    "    \n",
    "    # trip duration\n",
    "    cur_trip_duration = duration - meter_waiting - meter_waiting_till_pickup\n",
    "    trip_duration.append(cur_trip_duration)\n",
    "    duration_bucket.append(int(math.ceil(cur_trip_duration / 50)))\n",
    "    \n",
    "    if(duration != 0):\n",
    "        is_duration_zero.append(0)\n",
    "    else:\n",
    "        is_duration_zero.append(1)\n",
    "    \n",
    "    # trip distance\n",
    "    cur_trip_distance = float(great_circle((drop_lat, drop_lon),(pick_lat, pick_lon)).kilometers)\n",
    "    trip_distance.append(cur_trip_distance)\n",
    "    \n",
    "    # trip distance to duration\n",
    "    try:\n",
    "        cur_dist_to_dur = cur_trip_distance / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_dist_to_dur  = 0\n",
    "    distance_to_duration.append(cur_dist_to_dur)\n",
    "    \n",
    "    # trip fare to trip duration\n",
    "    try:\n",
    "        cur_fare_to_duration = cur_trip_fare / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_duration  = 0\n",
    "    fare_to_duration.append(cur_fare_to_duration)\n",
    "    \n",
    "    # trip fare to trip distance\n",
    "    try:\n",
    "        cur_fare_to_distance = cur_trip_fare / cur_trip_distance\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_distance  = 0\n",
    "    fare_to_distance.append(cur_fare_to_distance)\n",
    "    \n",
    "    # trip waiting fare to waiting duration\n",
    "    try:\n",
    "        cur_waiting_fare_to_waiting_dur = meter_waiting_fare / meter_waiting\n",
    "    except ZeroDivisionError:\n",
    "        cur_waiting_fare_to_waiting_dur  = 0\n",
    "    waiting_fare_to_waiting_duration.append(cur_waiting_fare_to_waiting_dur)\n",
    "    \n",
    "    # trip fare to waiting fare\n",
    "    try:\n",
    "        cur_fare_waiting_gap = (fare - meter_waiting_fare) / fare\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_waiting_gap  = 0\n",
    "    fare_waiting_gap.append(cur_fare_waiting_gap)\n",
    "    \n",
    "    # additional fare greater than 250\n",
    "    if(additional_fare > 250):\n",
    "        additional_fare_greater_than_250.append(1)\n",
    "    else:\n",
    "        additional_fare_greater_than_250.append(0)\n",
    "    \n",
    "    # time duration\n",
    "    # pickup time\n",
    "    month, day, y_hm = int(pickup_time[0]), int(pickup_time[1]), pickup_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    pickup_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # drop time\n",
    "    month, day, y_hm = int(drop_time[0]), int(drop_time[1]), drop_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    drop_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # duration\n",
    "    cur_duration_from_time = (drop_time - pickup_time).seconds\n",
    "    duration_from_time.append(cur_duration_from_time)\n",
    "    duration_error.append(cur_duration_from_time - duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append new columns to dataset\n",
    "dataset['trip_fare'] = trip_fare\n",
    "dataset['trip_duration'] = trip_duration\n",
    "dataset['trip_distance'] = trip_distance\n",
    "dataset['distance_to_duration'] = distance_to_duration\n",
    "dataset['fare_to_duration'] = fare_to_duration\n",
    "dataset['fare_to_distance'] = fare_to_distance\n",
    "dataset['waiting_fare_to_waiting_duration'] = waiting_fare_to_waiting_duration\n",
    "dataset['duration_from_time'] = duration_from_time\n",
    "dataset['duration_error'] = duration_error\n",
    "dataset['duration_bucket'] = duration_bucket\n",
    "dataset['fare_bucket'] = fare_bucket\n",
    "\n",
    "dataset['fare_waiting_gap'] = fare_waiting_gap\n",
    "dataset['additional_fare_greater_than_250'] = additional_fare_greater_than_250\n",
    "dataset['is_duration_zero'] = is_duration_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column average values\n",
    "avg_fare = dataset['fare'].mean()\n",
    "avg_trip_fare = dataset['trip_fare'].mean()\n",
    "avg_waiting_fare = dataset['meter_waiting_fare'].mean()\n",
    "avg_fare_to_distance = dataset['fare_to_distance'].mean()\n",
    "avg_waiting_fare_to_duration = dataset['waiting_fare_to_waiting_duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new columns\n",
    "is_invalid_total_fare = []\n",
    "div_from_avg_total_fare = []\n",
    "div_from_avg_waiting_fare = []\n",
    "div_from_avg_waiting_fare_to_waiting_duration = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each row in the dataset\n",
    "for row in dataset.itertuples():\n",
    "    fare = float(row.fare)\n",
    "    trip_fare = float(row.trip_fare)\n",
    "    meter_waiting_fare = float(row.meter_waiting_fare)\n",
    "    additional_fare = float(row.additional_fare)\n",
    "    \n",
    "    fare_to_distance = float(row.fare_to_distance)\n",
    "    waiting_fare_to_waiting_duration = float(row.waiting_fare_to_waiting_duration)\n",
    "    \n",
    "    # total fare less than or equal to zero\n",
    "    if(fare-meter_waiting_fare-additional_fare <= 0):\n",
    "        is_invalid_total_fare.append(1)\n",
    "    else:\n",
    "        is_invalid_total_fare.append(0)\n",
    "        \n",
    "    # diviation from average\n",
    "    div_from_avg_total_fare.append(fare - avg_fare)\n",
    "    div_from_avg_waiting_fare.append(meter_waiting_fare - avg_waiting_fare)\n",
    "    div_from_avg_waiting_fare_to_waiting_duration.append(waiting_fare_to_waiting_duration - avg_waiting_fare_to_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append new columns to dataset\n",
    "dataset['is_invalid_total_fare'] = is_invalid_total_fare\n",
    "dataset['div_from_avg_total_fare'] = div_from_avg_total_fare\n",
    "dataset['div_from_avg_waiting_fare'] = div_from_avg_waiting_fare\n",
    "dataset['div_from_avg_waiting_fare_to_waiting_duration'] = div_from_avg_waiting_fare_to_waiting_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling values into 0-1 range\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "features = [\n",
    "    'additional_fare',\n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup',\n",
    "    'pick_lat',\n",
    "    'pick_lon',\n",
    "    'drop_lat',\n",
    "    'drop_lon',\n",
    "    'fare',\n",
    "    'trip_fare',\n",
    "    'trip_duration',\n",
    "    'trip_distance',\n",
    "    'distance_to_duration',\n",
    "    'fare_to_duration',\n",
    "    'fare_to_distance',\n",
    "    'waiting_fare_to_waiting_duration', \n",
    "    'duration_from_time',\n",
    "    'duration_error',\n",
    "    'duration_bucket',\n",
    "    'fare_bucket'\n",
    "]\n",
    "\n",
    "dataset[features] = scaler.fit_transform(dataset[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into training and testing again\n",
    "\n",
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "test.drop(labels=['label'], axis=1, inplace=True)\n",
    "\n",
    "train['label'] = train['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time'\n",
    "]\n",
    "\n",
    "train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train['label']\n",
    "# X = train.drop(labels=['label'], axis=1)\n",
    "\n",
    "# # apply SelectKBest class to extract top 20 best features\n",
    "# bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "# fit = bestfeatures.fit(X, y)\n",
    "# dfscores = pd.DataFrame(fit.scores_)\n",
    "# dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# # concat two dataframes for better visualization\n",
    "# featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "# featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
    "# print(featureScores.nlargest(40, 'Score'))  #print 40 best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop less important columns\n",
    "labels_to_drop = [\n",
    "#     'trip_distance',\n",
    "#     'fare_to_duration',\n",
    "#     'trip_duration',\n",
    "#     'distance_to_duration',\n",
    "#     'duration_error',\n",
    "#     'meter_waiting_till_pickup',\n",
    "#     'additional_fare'\n",
    "]\n",
    "\n",
    "# train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Evaluating Basic XGBoost Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperate train features and label\n",
    "\n",
    "y_train = train['label']\n",
    "X_train = train.drop(labels='label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score: 0.9767\n"
     ]
    }
   ],
   "source": [
    "## model definition\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "## evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Mean F1 Score: %.4f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Handle Class Imbalancy - Weighted XGBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 13925, 0: 1402})\n",
      "Estimate: 9.932\n",
      "Approximate Estimate: 10\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "estimate = counter[1] / counter[0]\n",
    "\n",
    "print(counter)\n",
    "print('Estimate: %.3f' % estimate)\n",
    "\n",
    "estimate = round(estimate)\n",
    "print('Approximate Estimate: %i' % estimate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score: 0.9759\n"
     ]
    }
   ],
   "source": [
    "## model definition\n",
    "model = XGBClassifier(random_state=42, scale_pos_weight=estimate)\n",
    "\n",
    "## evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Mean F1 Score: %.4f' % np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tune for the Class Weight - Weighted XGBoost GridSearchCV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 20]\n",
    "param_grid = dict(scale_pos_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=42)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.976748 using {'scale_pos_weight': 1}\n",
      "0.976748 (0.003030) with: {'scale_pos_weight': 1}\n",
      "0.976566 (0.002406) with: {'scale_pos_weight': 3}\n",
      "0.976319 (0.002207) with: {'scale_pos_weight': 5}\n",
      "0.976116 (0.001935) with: {'scale_pos_weight': 7}\n",
      "0.976227 (0.002208) with: {'scale_pos_weight': 9}\n",
      "0.975875 (0.002089) with: {'scale_pos_weight': 10}\n",
      "0.975870 (0.002225) with: {'scale_pos_weight': 11}\n",
      "0.975714 (0.002176) with: {'scale_pos_weight': 12}\n",
      "0.975775 (0.002045) with: {'scale_pos_weight': 14}\n",
      "0.975893 (0.002294) with: {'scale_pos_weight': 15}\n",
      "0.975973 (0.002272) with: {'scale_pos_weight': 20}\n"
     ]
    }
   ],
   "source": [
    "## report\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross Validation to Tune Hiper Parameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=2600, num=10)]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(1, 15, num=1)]\n",
    "max_depth.append(None)\n",
    "\n",
    "learning_rate = [0.1, 0.01, 0.001, 0.0001]\n",
    "gamma = [0, 0.1, 1, 2, 5]\n",
    "reg_alpha = [0.01, 0.1, 1, 10]\n",
    "reg_lambda = [0.01, 0.1, 1, 10]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "tree_method = ['auto']\n",
    "num_parallel_tree = [1, 2, 5, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the random grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate': learning_rate,\n",
    "    'gamma': gamma,\n",
    "    'reg_alpha': reg_alpha,\n",
    "    'reg_lambda': reg_lambda,\n",
    "    'booster': booster,\n",
    "    'tree_method': tree_method,\n",
    "    'num_parallel_tree': num_parallel_tree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random = XGBClassifier(random_state=42, scale_pos_weight=1, n_jobs=-1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=42)\n",
    "\n",
    "random_grid = GridSearchCV(estimator=model_random, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n",
    "random_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best parameters\n",
    "random_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## GridSearch on best range\n",
    "# param_grid = {\n",
    "#     'n_estimators': n_estimators,\n",
    "#     'max_depth': max_depth,\n",
    "#     'learning_rate': learning_rate,\n",
    "#     'gamma': gamma,\n",
    "#     'reg_alpha': reg_alpha,\n",
    "#     'reg_lambda': reg_lambda,\n",
    "#     'booster': booster,\n",
    "#     'tree_method': tree_method,\n",
    "#     'num_parallel_tree': num_parallel_tree\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(random_state=42, scale_pos_weight=1, n_jobs=-1)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=42)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n",
    "# grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train for the Selected Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Accuracy : 97.725\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    scale_pos_weight = 1,\n",
    "    n_jobs = -1,\n",
    "    random_state = 42,\n",
    "    n_estimators = 800,\n",
    "    max_depth = 15,\n",
    "    learning_rate = 0.1,\n",
    "    gamma = 0,\n",
    "    reg_alpha = 0.1,\n",
    "    reg_lambda = 0.1,\n",
    "    booster = 'gbtree',\n",
    "    tree_method = 'auto',\n",
    "    num_parallel_tree = 1\n",
    ")\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "rfc_scores = []\n",
    "score = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "rfc_scores.append(score.mean())\n",
    "\n",
    "print('% Accuracy :', round(score.mean()*100, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=800, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=42, reg_alpha=0.1,\n",
       "              reg_lambda=0.1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## parameters and accuracies\n",
    "\n",
    "# n_estimators      : 800     1000    600     800     800     800\n",
    "# max_depth         : 2       2       2       5       10      15\n",
    "# learning_rate     : 0.1     0.1     0.1     0.1     0.1     0.1\n",
    "# gamma             : 0       0       0       0       0       0\n",
    "# reg_alpha         : 0.01    0.01    0.01    0.01    0.01    0.01\n",
    "# reg_lambda        : 0.01    0.01    0.01    0.01    0.01    0.01\n",
    "# booster           : gbtree  gbtree  gbtree  gbtree  gbtree  gbtree\n",
    "# num_parallel_tree : 1       1       1       1       1       1\n",
    "# accuracy          : 97.70   97.69   97.68   97.67   97.69   97.72\n",
    "    \n",
    "\n",
    "# n_estimators      : 800     800     800     800     800     800\n",
    "# max_depth         : 15      15      15      15      15      15\n",
    "# learning_rate     : 0.01    0.001   0.1     0.1     0.1     0.1\n",
    "# gamma             : 0       0       1       2       5       0.1\n",
    "# reg_alpha         : 0.01    0.01    0.01    0.01    0.01    0.01\n",
    "# reg_lambda        : 0.01    0.01    0.01    0.01    0.01    0.01\n",
    "# booster           : gbtree  gbtree  gbtree  gbtree  gbtree  gbtree\n",
    "# num_parallel_tree : 1       1       1       1       1       1\n",
    "# accuracy          : 97.68   97.45   97.68   97.69   97.69   97.71\n",
    "    \n",
    "\n",
    "# n_estimators      : 800     800     800     800     800     800\n",
    "# max_depth         : 15      15      15      15      15      15\n",
    "# learning_rate     : 0.1     0.1     0.1     0.1     0.1     0.1\n",
    "# gamma             : 0.01    0.001   0       0       0       0\n",
    "# reg_alpha         : 0.01    0.01    0.1     1       0.1     0.1\n",
    "# reg_lambda        : 0.01    0.01    0.1     1       0.1     0.1\n",
    "# booster           : gbtree  gbtree  gbtree  gbtree  gbtree  gbtree\n",
    "# num_parallel_tree : 1       1       1       1       5       8\n",
    "# accuracy          : 97.71   97.70   97.725  97.70   97.72   97.71\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting and Preparing the Submission</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "trip_ids = test.tripid\n",
    "\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time',\n",
    "#     'trip_distance',\n",
    "#     'fare_to_duration',\n",
    "#     'trip_duration',\n",
    "#     'distance_to_duration',\n",
    "#     'duration_error',\n",
    "#     'meter_waiting_till_pickup',\n",
    "#     'additional_fare'\n",
    "]\n",
    "\n",
    "test = test.drop(labels=labels_to_drop, axis=1)\n",
    "\n",
    "predictions = model.predict(test)\n",
    "\n",
    "output = pd.DataFrame({'tripid': trip_ids, 'prediction': predictions})\n",
    "output.to_csv('../../submissions/160253h_submission_15.csv', index=False)\n",
    "print('Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training.\n",
    "\n",
    "KNNImputer to impute missing values.\n",
    "\n",
    "with cross validation (to tune hiper-parameters).\n",
    "\n",
    "with feature engineering (added 16 new features).\n",
    "\n",
    "datetime columns have dropped (new features added).\n",
    "\n",
    "[model: XGBoost Classifier]\n",
    "\n",
    "score: 0.9787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
