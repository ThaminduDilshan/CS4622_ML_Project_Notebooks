{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries and Modules</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy\n",
    "# !pip install scikit-learn==0.22.1 --user\n",
    "# !pip install imblearn --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, RandomizedSearchCV\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Datasets\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Intuition on the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189123628</td>\n",
       "      <td>10.5</td>\n",
       "      <td>834.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11/1/2019 0:20</td>\n",
       "      <td>11/1/2019 0:34</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189125358</td>\n",
       "      <td>10.5</td>\n",
       "      <td>791.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11/1/2019 0:56</td>\n",
       "      <td>11/1/2019 1:09</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189125719</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11/1/2019 1:08</td>\n",
       "      <td>11/1/2019 1:26</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189127273</td>\n",
       "      <td>10.5</td>\n",
       "      <td>598.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11/1/2019 2:27</td>\n",
       "      <td>11/1/2019 2:37</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.30</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189128020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/1/2019 3:34</td>\n",
       "      <td>11/1/2019 3:51</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "0  189123628             10.5     834.0           56.0              0.0000   \n",
       "1  189125358             10.5     791.0           47.0              0.0000   \n",
       "2  189125719             10.5    1087.0           80.0              0.0000   \n",
       "3  189127273             10.5     598.0          271.0             15.6638   \n",
       "4  189128020              NaN       NaN            NaN                 NaN   \n",
       "\n",
       "   meter_waiting_till_pickup     pickup_time       drop_time  pick_lat  \\\n",
       "0                       64.0  11/1/2019 0:20  11/1/2019 0:34   6.86252   \n",
       "1                      134.0  11/1/2019 0:56  11/1/2019 1:09   6.88589   \n",
       "2                       61.0  11/1/2019 1:08  11/1/2019 1:26   6.90839   \n",
       "3                       68.0  11/1/2019 2:27  11/1/2019 2:37   6.92570   \n",
       "4                        NaN  11/1/2019 3:34  11/1/2019 3:51   6.87441   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon    fare    label  \n",
       "0   79.8993   6.90330   79.8783  270.32  correct  \n",
       "1   79.8984   6.91373   79.8923  197.85  correct  \n",
       "2   79.8651   6.93669   79.9146  301.64  correct  \n",
       "3   79.8895   6.92748   79.8971   82.30  correct  \n",
       "4   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213284604</td>\n",
       "      <td>10.5</td>\n",
       "      <td>924</td>\n",
       "      <td>42</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>148</td>\n",
       "      <td>2/1/2020 0:38</td>\n",
       "      <td>2/1/2020 0:53</td>\n",
       "      <td>6.83454</td>\n",
       "      <td>79.8750</td>\n",
       "      <td>6.77490</td>\n",
       "      <td>79.8840</td>\n",
       "      <td>289.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213286352</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4249</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>91</td>\n",
       "      <td>2/1/2020 1:02</td>\n",
       "      <td>2/1/2020 2:13</td>\n",
       "      <td>6.91168</td>\n",
       "      <td>79.8723</td>\n",
       "      <td>6.55091</td>\n",
       "      <td>79.9706</td>\n",
       "      <td>1912.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>213293973</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1552</td>\n",
       "      <td>255</td>\n",
       "      <td>2.6588</td>\n",
       "      <td>23</td>\n",
       "      <td>2/1/2020 5:02</td>\n",
       "      <td>2/1/2020 5:28</td>\n",
       "      <td>6.92145</td>\n",
       "      <td>79.8478</td>\n",
       "      <td>6.90539</td>\n",
       "      <td>79.8989</td>\n",
       "      <td>394.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213294622</td>\n",
       "      <td>10.5</td>\n",
       "      <td>462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>2/1/2020 5:30</td>\n",
       "      <td>2/1/2020 5:38</td>\n",
       "      <td>6.77433</td>\n",
       "      <td>79.9416</td>\n",
       "      <td>6.80401</td>\n",
       "      <td>79.9407</td>\n",
       "      <td>154.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213298687</td>\n",
       "      <td>10.5</td>\n",
       "      <td>814</td>\n",
       "      <td>392</td>\n",
       "      <td>12.3692</td>\n",
       "      <td>69</td>\n",
       "      <td>2/1/2020 7:00</td>\n",
       "      <td>2/1/2020 7:14</td>\n",
       "      <td>6.97968</td>\n",
       "      <td>79.9130</td>\n",
       "      <td>6.98875</td>\n",
       "      <td>79.8914</td>\n",
       "      <td>147.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "0  213284604             10.5       924             42              2.4486   \n",
       "1  213286352             10.5      4249             20              0.0000   \n",
       "2  213293973             10.5      1552            255              2.6588   \n",
       "3  213294622             10.5       462             16              0.0000   \n",
       "4  213298687             10.5       814            392             12.3692   \n",
       "\n",
       "   meter_waiting_till_pickup    pickup_time      drop_time  pick_lat  \\\n",
       "0                        148  2/1/2020 0:38  2/1/2020 0:53   6.83454   \n",
       "1                         91  2/1/2020 1:02  2/1/2020 2:13   6.91168   \n",
       "2                         23  2/1/2020 5:02  2/1/2020 5:28   6.92145   \n",
       "3                        198  2/1/2020 5:30  2/1/2020 5:38   6.77433   \n",
       "4                         69  2/1/2020 7:00  2/1/2020 7:14   6.97968   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon     fare  \n",
       "0   79.8750   6.77490   79.8840   289.27  \n",
       "1   79.8723   6.55091   79.9706  1912.70  \n",
       "2   79.8478   6.90539   79.8989   394.00  \n",
       "3   79.9416   6.80401   79.9407   154.32  \n",
       "4   79.9130   6.98875   79.8914   147.47  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17176 entries, 0 to 17175\n",
      "Data columns (total 14 columns):\n",
      "tripid                       17176 non-null int64\n",
      "additional_fare              16974 non-null float64\n",
      "duration                     16974 non-null float64\n",
      "meter_waiting                16974 non-null float64\n",
      "meter_waiting_fare           16974 non-null float64\n",
      "meter_waiting_till_pickup    16974 non-null float64\n",
      "pickup_time                  17176 non-null object\n",
      "drop_time                    17176 non-null object\n",
      "pick_lat                     17176 non-null float64\n",
      "pick_lon                     17176 non-null float64\n",
      "drop_lat                     17176 non-null float64\n",
      "drop_lon                     17176 non-null float64\n",
      "fare                         17039 non-null float64\n",
      "label                        17176 non-null object\n",
      "dtypes: float64(10), int64(1), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17176, 14)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8576 entries, 0 to 8575\n",
      "Data columns (total 13 columns):\n",
      "tripid                       8576 non-null int64\n",
      "additional_fare              8576 non-null float64\n",
      "duration                     8576 non-null int64\n",
      "meter_waiting                8576 non-null int64\n",
      "meter_waiting_fare           8576 non-null float64\n",
      "meter_waiting_till_pickup    8576 non-null int64\n",
      "pickup_time                  8576 non-null object\n",
      "drop_time                    8576 non-null object\n",
      "pick_lat                     8576 non-null float64\n",
      "pick_lon                     8576 non-null float64\n",
      "drop_lat                     8576 non-null float64\n",
      "drop_lon                     8576 non-null float64\n",
      "fare                         8576 non-null float64\n",
      "dtypes: float64(7), int64(4), object(2)\n",
      "memory usage: 871.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 13)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting label values into 0,1 instead of correct, incorrect\n",
    "\n",
    "train.label = train.label.map(dict(correct=1, incorrect=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                         0\n",
       "additional_fare              202\n",
       "duration                     202\n",
       "meter_waiting                202\n",
       "meter_waiting_fare           202\n",
       "meter_waiting_till_pickup    202\n",
       "pickup_time                    0\n",
       "drop_time                      0\n",
       "pick_lat                       0\n",
       "pick_lon                       0\n",
       "drop_lat                       0\n",
       "drop_lon                       0\n",
       "fare                         137\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check for missing values in the dataset\n",
    "\n",
    "# train.isna().head()\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill missing values by mean of the column\n",
    "\n",
    "# train.fillna(train.mean(), inplace=True)\n",
    "\n",
    "# imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "# imputer.fit(train.iloc[:,[1,2,3,4,5,12]])\n",
    "# train.iloc[:,[1,2,3,4,5,12]] = imputer.transform(train.iloc[:,[1,2,3,4,5,12]])\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "train.iloc[:,[1,2,3,4,5,12]] = imputer.fit_transform(train.iloc[:,[1,2,3,4,5,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "label                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join train and test datasets in order to obtain the same number of features during categorical conversion\n",
    "train_len = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Advanced Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new feature columns\n",
    "trip_fare = []\n",
    "trip_duration = []\n",
    "trip_distance = []\n",
    "\n",
    "distance_to_duration = []\n",
    "fare_to_duration = []\n",
    "fare_to_distance = []\n",
    "waiting_fare_to_waiting_duration = []\n",
    "\n",
    "duration_from_time = []\n",
    "duration_error = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each row in the dataset\n",
    "for row in dataset.itertuples():\n",
    "    fare = float(row.fare)\n",
    "    additional_fare = float(row.additional_fare)\n",
    "    meter_waiting_fare = float(row.meter_waiting_fare)\n",
    "    \n",
    "    meter_waiting = row.meter_waiting\n",
    "    meter_waiting_till_pickup = row.meter_waiting_till_pickup\n",
    "    duration = row.duration\n",
    "    \n",
    "    pick_lat = row.pick_lat\n",
    "    pick_lon = row.pick_lon\n",
    "    drop_lat = row.drop_lat\n",
    "    drop_lon = row.drop_lon\n",
    "    \n",
    "    pickup_time = row.pickup_time.split('/')\n",
    "    drop_time = row.drop_time.split('/')\n",
    "    \n",
    "    # total fare for the trip\n",
    "    cur_trip_fare = fare - (additional_fare + meter_waiting_fare)\n",
    "    trip_fare.append(cur_trip_fare)\n",
    "    \n",
    "    # trip duration\n",
    "    cur_trip_duration = duration - meter_waiting - meter_waiting_till_pickup\n",
    "    trip_duration.append(cur_trip_duration)\n",
    "    \n",
    "    # trip distance\n",
    "    cur_trip_distance = float(great_circle((drop_lat, drop_lon),(pick_lat, pick_lon)).kilometers)\n",
    "    trip_distance.append(cur_trip_distance)\n",
    "    \n",
    "    # trip distance to duration\n",
    "    try:\n",
    "        cur_dist_to_dur = cur_trip_distance / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_dist_to_dur  = 0\n",
    "    distance_to_duration.append(cur_dist_to_dur)\n",
    "    \n",
    "    # trip fare to trip duration\n",
    "    try:\n",
    "        cur_fare_to_duration = cur_trip_fare / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_duration  = 0\n",
    "    fare_to_duration.append(cur_fare_to_duration)\n",
    "    \n",
    "    # trip fare to trip distance\n",
    "    try:\n",
    "        cur_fare_to_distance = cur_trip_fare / cur_trip_distance\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_distance  = 0\n",
    "    fare_to_distance.append(cur_fare_to_distance)\n",
    "    \n",
    "    # trip waiting fare to waiting duration\n",
    "    try:\n",
    "        cur_waiting_fare_to_waiting_dur = meter_waiting_fare / meter_waiting\n",
    "    except ZeroDivisionError:\n",
    "        cur_waiting_fare_to_waiting_dur  = 0\n",
    "    waiting_fare_to_waiting_duration.append(cur_waiting_fare_to_waiting_dur)\n",
    "    \n",
    "    # time duration\n",
    "    # pickup time\n",
    "    month, day, y_hm = int(pickup_time[0]), int(pickup_time[1]), pickup_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    pickup_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # drop time\n",
    "    month, day, y_hm = int(drop_time[0]), int(drop_time[1]), drop_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    drop_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # duration\n",
    "    cur_duration_from_time = (drop_time - pickup_time).seconds\n",
    "    duration_from_time.append(cur_duration_from_time)\n",
    "    duration_error.append(cur_duration_from_time - duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append new columns to dataset\n",
    "dataset['trip_fare'] = trip_fare\n",
    "dataset['trip_duration'] = trip_duration\n",
    "dataset['trip_distance'] = trip_distance\n",
    "dataset['distance_to_duration'] = distance_to_duration\n",
    "dataset['fare_to_duration'] = fare_to_duration\n",
    "dataset['fare_to_distance'] = fare_to_distance\n",
    "dataset['waiting_fare_to_waiting_duration'] = waiting_fare_to_waiting_duration\n",
    "dataset['duration_from_time'] = duration_from_time\n",
    "dataset['duration_error'] = duration_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling values into 0-1 range\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "features = [\n",
    "    'additional_fare',\n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup',\n",
    "    'pick_lat',\n",
    "    'pick_lon',\n",
    "    'drop_lat',\n",
    "    'drop_lon',\n",
    "    'fare',\n",
    "    'trip_fare',\n",
    "    'trip_duration',\n",
    "    'trip_distance',\n",
    "    'distance_to_duration',\n",
    "    'fare_to_duration',\n",
    "    'fare_to_distance',\n",
    "    'waiting_fare_to_waiting_duration', \n",
    "    'duration_from_time',\n",
    "    'duration_error'\n",
    "]\n",
    "\n",
    "dataset[features] = scaler.fit_transform(dataset[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into training and testing again\n",
    "\n",
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "test.drop(labels=['label'], axis=1, inplace=True)\n",
    "\n",
    "train['label'] = train['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time'\n",
    "]\n",
    "\n",
    "train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Specs      Score\n",
      "6                 meter_waiting_fare  43.042000\n",
      "5                      meter_waiting  40.970053\n",
      "17                duration_from_time  33.113976\n",
      "4                               fare  23.025250\n",
      "3                           duration  17.022813\n",
      "10                         trip_fare  13.165229\n",
      "16  waiting_fare_to_waiting_duration   8.134421\n",
      "9                           pick_lon   6.718608\n",
      "15                  fare_to_distance   2.712277\n",
      "0                    additional_fare   1.451899\n",
      "7          meter_waiting_till_pickup   0.614306\n",
      "8                           pick_lat   0.255063\n",
      "18                    duration_error   0.011158\n",
      "1                           drop_lat   0.009238\n",
      "2                           drop_lon   0.001652\n",
      "13              distance_to_duration   0.001194\n",
      "11                     trip_duration   0.000408\n",
      "14                  fare_to_duration   0.000282\n",
      "12                     trip_distance   0.000145\n"
     ]
    }
   ],
   "source": [
    "y = train['label']\n",
    "X = train.drop(labels=['label'], axis=1)\n",
    "\n",
    "# apply SelectKBest class to extract top 20 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "fit = bestfeatures.fit(X, y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(30, 'Score'))  #print 10 best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop less important columns\n",
    "labels_to_drop = [\n",
    "    'trip_distance',\n",
    "    'fare_to_duration',\n",
    "    'trip_duration',\n",
    "    'distance_to_duration',\n",
    "    'duration_error',\n",
    "    'meter_waiting_till_pickup',\n",
    "    'additional_fare'\n",
    "]\n",
    "\n",
    "# train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Testing Different Algorithms</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperate train features and label\n",
    "\n",
    "y_train = train['label']\n",
    "X_train = train.drop(labels='label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValerrors</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949262</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>DecisionTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.956690</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974590</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.972824</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.962088</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>MultipleLayerPerceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.959261</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>KNeighboors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.949444</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.951061</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CrossValMeans  CrossValerrors                   Algorithm\n",
       "0       0.949262        0.000341                         SVC\n",
       "1       0.957123        0.002290                DecisionTree\n",
       "2       0.956690        0.002501                    AdaBoost\n",
       "3       0.974590        0.002886                RandomForest\n",
       "4       0.974199        0.001770                  ExtraTrees\n",
       "5       0.972824        0.001934            GradientBoosting\n",
       "6       0.962088        0.001696     MultipleLayerPerceptron\n",
       "7       0.959261        0.000952                 KNeighboors\n",
       "8       0.949444        0.000592          LogisticRegression\n",
       "9       0.951061        0.000648  LinearDiscriminantAnalysis"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test different algorithms\n",
    "random_state = 42\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers:\n",
    "    cv_results.append(\n",
    "        cross_val_score(classifier, X_train, y=y_train, scoring=\"f1\", cv=kfold, n_jobs=4)\n",
    "    )\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n",
    "\n",
    "cv_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Handle Class Imbalancy</h2>\n",
    "<h3>Apply SMOTE to Generate Synthetic Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1681, 1: 15495}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique, count)}\n",
    "y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=42)\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, count = np.unique(y_train, return_counts=True)\n",
    "# y_train_dict_value_count = {k:v for (k,v) in zip(unique, count)}\n",
    "# y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apply Class Weights to Handle Imbalanced Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.10886377, 0.5542433 ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = {'class_weight': [{0:x, 1: 1.0-x} for x in weights]},\n",
    "    scoring = 'f1',\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "print('Best Parameters: ', grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc2bb619550>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out = pd.DataFrame({'score': grid_result.cv_results_['mean_test_score'], 'weight': weights})\n",
    "\n",
    "data_out.plot(x='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972896</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973058</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973236</td>\n",
       "      <td>0.144737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973166</td>\n",
       "      <td>0.192105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.239474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.972929</td>\n",
       "      <td>0.286842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973547</td>\n",
       "      <td>0.334211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973689</td>\n",
       "      <td>0.381579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973753</td>\n",
       "      <td>0.428947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.973464</td>\n",
       "      <td>0.476316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973634</td>\n",
       "      <td>0.523684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973870</td>\n",
       "      <td>0.571053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.973489</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.665789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.973439</td>\n",
       "      <td>0.713158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.760526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973497</td>\n",
       "      <td>0.807895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.972875</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.902632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.972246</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score    weight\n",
       "0   0.972896  0.050000\n",
       "1   0.973058  0.097368\n",
       "2   0.973236  0.144737\n",
       "3   0.973166  0.192105\n",
       "4   0.973051  0.239474\n",
       "5   0.972929  0.286842\n",
       "6   0.973547  0.334211\n",
       "7   0.973689  0.381579\n",
       "8   0.973753  0.428947\n",
       "9   0.973464  0.476316\n",
       "10  0.973634  0.523684\n",
       "11  0.973870  0.571053\n",
       "12  0.973489  0.618421\n",
       "13  0.972789  0.665789\n",
       "14  0.973439  0.713158\n",
       "15  0.973485  0.760526\n",
       "16  0.973497  0.807895\n",
       "17  0.972875  0.855263\n",
       "18  0.972977  0.902632\n",
       "19  0.972246  0.950000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = grid_result.best_params_\n",
    "# class_weights\n",
    "\n",
    "class_weights = {'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross Validation for the Selected Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263},\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "\n",
    "# number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 95.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 105.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=False),\n",
       "                   error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight={0: 0.5710526315789474,\n",
       "                                                                  1: 0.42894736842105263},\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "\n",
    "model_random = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=kfold, verbose=2, random_state=42, n_jobs=-1, scoring='f1')\n",
    "model_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Best parameters\n",
    "model_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GridSearch on best range\n",
    "param_grid = {\n",
    "    'n_estimators': [700, 800, 900],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [10, 12],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 33.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight={0: 0.5710526315789474,\n",
       "                                                            1: 0.42894736842105263},\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              m...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [20, 30],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [10, 12],\n",
       "                         'n_estimators': [700, 800, 900]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, verbose=2, n_jobs=-1, scoring='f1')\n",
    "model_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 900}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train for the Selected Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Accuracy : 97.4896\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    max_depth=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    n_estimators=900,\n",
    "    **class_weights\n",
    ")\n",
    "\n",
    "rfc_scores = []\n",
    "score = cross_val_score(model, X_train, y_train, cv=kfold, scoring='f1')\n",
    "rfc_scores.append(score.mean())\n",
    "\n",
    "print('% Accuracy :', round(score.mean()*100, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.5710526315789474,\n",
       "                                     1: 0.42894736842105263},\n",
       "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=12,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=900,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting and Preparing the Submission</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "trip_ids = test.tripid\n",
    "\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time',\n",
    "#     'trip_distance',\n",
    "#     'fare_to_duration',\n",
    "#     'trip_duration',\n",
    "#     'distance_to_duration',\n",
    "#     'duration_error',\n",
    "#     'meter_waiting_till_pickup',\n",
    "#     'additional_fare'\n",
    "]\n",
    "\n",
    "test = test.drop(labels=labels_to_drop, axis=1)\n",
    "\n",
    "predictions = model.predict(test)\n",
    "\n",
    "output = pd.DataFrame({'tripid': trip_ids, 'prediction': predictions})\n",
    "output.to_csv('../submissions/160253h_submission_07.csv', index=False)\n",
    "print('Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training.\n",
    "\n",
    "KNNImputer to impute missing values.\n",
    "\n",
    "with cross validation (to tune hiper-parameters).\n",
    "\n",
    "with feature engineering (added 9 new features).\n",
    "\n",
    "datetime columns have dropped (new features added).\n",
    "\n",
    "[model: Random Forest Classifier]\n",
    "\n",
    "score: 0.97944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
