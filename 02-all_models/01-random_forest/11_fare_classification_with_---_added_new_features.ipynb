{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries and Modules</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy\n",
    "# !pip install scikit-learn==0.22.1 --user\n",
    "# !pip install imblearn --user\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, RandomizedSearchCV\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Datasets\n",
    "train = pd.read_csv('../../data/weka_processed/train_pro.csv')\n",
    "test = pd.read_csv('../../data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Intuition on the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189123628</td>\n",
       "      <td>10.5</td>\n",
       "      <td>834</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>'11/1/2019 0:20'</td>\n",
       "      <td>'11/1/2019 0:34'</td>\n",
       "      <td>6.86252</td>\n",
       "      <td>79.8993</td>\n",
       "      <td>6.90330</td>\n",
       "      <td>79.8783</td>\n",
       "      <td>270.32</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189125358</td>\n",
       "      <td>10.5</td>\n",
       "      <td>791</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>'11/1/2019 0:56'</td>\n",
       "      <td>'11/1/2019 1:09'</td>\n",
       "      <td>6.88589</td>\n",
       "      <td>79.8984</td>\n",
       "      <td>6.91373</td>\n",
       "      <td>79.8923</td>\n",
       "      <td>197.85</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189125719</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1087</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>'11/1/2019 1:08'</td>\n",
       "      <td>'11/1/2019 1:26'</td>\n",
       "      <td>6.90839</td>\n",
       "      <td>79.8651</td>\n",
       "      <td>6.93669</td>\n",
       "      <td>79.9146</td>\n",
       "      <td>301.64</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189127273</td>\n",
       "      <td>10.5</td>\n",
       "      <td>598</td>\n",
       "      <td>271</td>\n",
       "      <td>15.6638</td>\n",
       "      <td>68</td>\n",
       "      <td>'11/1/2019 2:27'</td>\n",
       "      <td>'11/1/2019 2:37'</td>\n",
       "      <td>6.92570</td>\n",
       "      <td>79.8895</td>\n",
       "      <td>6.92748</td>\n",
       "      <td>79.8971</td>\n",
       "      <td>82.3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189128020</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>'11/1/2019 3:34'</td>\n",
       "      <td>'11/1/2019 3:51'</td>\n",
       "      <td>6.87441</td>\n",
       "      <td>79.8615</td>\n",
       "      <td>6.84478</td>\n",
       "      <td>79.9290</td>\n",
       "      <td>358.39</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid additional_fare duration meter_waiting meter_waiting_fare  \\\n",
       "0  189123628            10.5      834            56                  0   \n",
       "1  189125358            10.5      791            47                  0   \n",
       "2  189125719            10.5     1087            80                  0   \n",
       "3  189127273            10.5      598           271            15.6638   \n",
       "4  189128020               ?        ?             ?                  ?   \n",
       "\n",
       "  meter_waiting_till_pickup       pickup_time         drop_time  pick_lat  \\\n",
       "0                        64  '11/1/2019 0:20'  '11/1/2019 0:34'   6.86252   \n",
       "1                       134  '11/1/2019 0:56'  '11/1/2019 1:09'   6.88589   \n",
       "2                        61  '11/1/2019 1:08'  '11/1/2019 1:26'   6.90839   \n",
       "3                        68  '11/1/2019 2:27'  '11/1/2019 2:37'   6.92570   \n",
       "4                         ?  '11/1/2019 3:34'  '11/1/2019 3:51'   6.87441   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon    fare    label  \n",
       "0   79.8993   6.90330   79.8783  270.32  correct  \n",
       "1   79.8984   6.91373   79.8923  197.85  correct  \n",
       "2   79.8651   6.93669   79.9146  301.64  correct  \n",
       "3   79.8895   6.92748   79.8971    82.3  correct  \n",
       "4   79.8615   6.84478   79.9290  358.39  correct  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripid</th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213284604</td>\n",
       "      <td>10.5</td>\n",
       "      <td>924</td>\n",
       "      <td>42</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>148</td>\n",
       "      <td>2/1/2020 0:38</td>\n",
       "      <td>2/1/2020 0:53</td>\n",
       "      <td>6.83454</td>\n",
       "      <td>79.8750</td>\n",
       "      <td>6.77490</td>\n",
       "      <td>79.8840</td>\n",
       "      <td>289.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213286352</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4249</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>91</td>\n",
       "      <td>2/1/2020 1:02</td>\n",
       "      <td>2/1/2020 2:13</td>\n",
       "      <td>6.91168</td>\n",
       "      <td>79.8723</td>\n",
       "      <td>6.55091</td>\n",
       "      <td>79.9706</td>\n",
       "      <td>1912.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>213293973</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1552</td>\n",
       "      <td>255</td>\n",
       "      <td>2.6588</td>\n",
       "      <td>23</td>\n",
       "      <td>2/1/2020 5:02</td>\n",
       "      <td>2/1/2020 5:28</td>\n",
       "      <td>6.92145</td>\n",
       "      <td>79.8478</td>\n",
       "      <td>6.90539</td>\n",
       "      <td>79.8989</td>\n",
       "      <td>394.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213294622</td>\n",
       "      <td>10.5</td>\n",
       "      <td>462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>2/1/2020 5:30</td>\n",
       "      <td>2/1/2020 5:38</td>\n",
       "      <td>6.77433</td>\n",
       "      <td>79.9416</td>\n",
       "      <td>6.80401</td>\n",
       "      <td>79.9407</td>\n",
       "      <td>154.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213298687</td>\n",
       "      <td>10.5</td>\n",
       "      <td>814</td>\n",
       "      <td>392</td>\n",
       "      <td>12.3692</td>\n",
       "      <td>69</td>\n",
       "      <td>2/1/2020 7:00</td>\n",
       "      <td>2/1/2020 7:14</td>\n",
       "      <td>6.97968</td>\n",
       "      <td>79.9130</td>\n",
       "      <td>6.98875</td>\n",
       "      <td>79.8914</td>\n",
       "      <td>147.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "0  213284604             10.5       924             42              2.4486   \n",
       "1  213286352             10.5      4249             20              0.0000   \n",
       "2  213293973             10.5      1552            255              2.6588   \n",
       "3  213294622             10.5       462             16              0.0000   \n",
       "4  213298687             10.5       814            392             12.3692   \n",
       "\n",
       "   meter_waiting_till_pickup    pickup_time      drop_time  pick_lat  \\\n",
       "0                        148  2/1/2020 0:38  2/1/2020 0:53   6.83454   \n",
       "1                         91  2/1/2020 1:02  2/1/2020 2:13   6.91168   \n",
       "2                         23  2/1/2020 5:02  2/1/2020 5:28   6.92145   \n",
       "3                        198  2/1/2020 5:30  2/1/2020 5:38   6.77433   \n",
       "4                         69  2/1/2020 7:00  2/1/2020 7:14   6.97968   \n",
       "\n",
       "   pick_lon  drop_lat  drop_lon     fare  \n",
       "0   79.8750   6.77490   79.8840   289.27  \n",
       "1   79.8723   6.55091   79.9706  1912.70  \n",
       "2   79.8478   6.90539   79.8989   394.00  \n",
       "3   79.9416   6.80401   79.9407   154.32  \n",
       "4   79.9130   6.98875   79.8914   147.47  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15327 entries, 0 to 15326\n",
      "Data columns (total 14 columns):\n",
      "tripid                       15327 non-null int64\n",
      "additional_fare              15327 non-null object\n",
      "duration                     15327 non-null object\n",
      "meter_waiting                15327 non-null object\n",
      "meter_waiting_fare           15327 non-null object\n",
      "meter_waiting_till_pickup    15327 non-null object\n",
      "pickup_time                  15327 non-null object\n",
      "drop_time                    15327 non-null object\n",
      "pick_lat                     15327 non-null float64\n",
      "pick_lon                     15327 non-null float64\n",
      "drop_lat                     15327 non-null float64\n",
      "drop_lon                     15327 non-null float64\n",
      "fare                         15327 non-null object\n",
      "label                        15327 non-null object\n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15327, 14)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8576 entries, 0 to 8575\n",
      "Data columns (total 13 columns):\n",
      "tripid                       8576 non-null int64\n",
      "additional_fare              8576 non-null float64\n",
      "duration                     8576 non-null int64\n",
      "meter_waiting                8576 non-null int64\n",
      "meter_waiting_fare           8576 non-null float64\n",
      "meter_waiting_till_pickup    8576 non-null int64\n",
      "pickup_time                  8576 non-null object\n",
      "drop_time                    8576 non-null object\n",
      "pick_lat                     8576 non-null float64\n",
      "pick_lon                     8576 non-null float64\n",
      "drop_lat                     8576 non-null float64\n",
      "drop_lon                     8576 non-null float64\n",
      "fare                         8576 non-null float64\n",
      "dtypes: float64(7), int64(4), object(2)\n",
      "memory usage: 871.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning weka added unnecessary values\n",
    "\n",
    "train = train.replace({'?': np.nan})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting label values into 0,1 instead of correct, incorrect\n",
    "\n",
    "train.label = train.label.map(dict(correct=1, incorrect=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                         0\n",
       "additional_fare              196\n",
       "duration                     196\n",
       "meter_waiting                196\n",
       "meter_waiting_fare           196\n",
       "meter_waiting_till_pickup    196\n",
       "pickup_time                    0\n",
       "drop_time                      0\n",
       "pick_lat                       0\n",
       "pick_lon                       0\n",
       "drop_lat                       0\n",
       "drop_lon                       0\n",
       "fare                         133\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check for missing values in the dataset\n",
    "\n",
    "# train.isna().head()\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill missing values by mean of the column\n",
    "\n",
    "# train.fillna(train.mean(), inplace=True)\n",
    "\n",
    "# imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "# imputer.fit(train.iloc[:,[1,2,3,4,5,12]])\n",
    "# train.iloc[:,[1,2,3,4,5,12]] = imputer.transform(train.iloc[:,[1,2,3,4,5,12]])\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "train.iloc[:,[1,2,3,4,5,12]] = imputer.fit_transform(train.iloc[:,[1,2,3,4,5,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                       0\n",
       "additional_fare              0\n",
       "duration                     0\n",
       "meter_waiting                0\n",
       "meter_waiting_fare           0\n",
       "meter_waiting_till_pickup    0\n",
       "pickup_time                  0\n",
       "drop_time                    0\n",
       "pick_lat                     0\n",
       "pick_lon                     0\n",
       "drop_lat                     0\n",
       "drop_lon                     0\n",
       "fare                         0\n",
       "label                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join train and test datasets in order to obtain the same number of features during categorical conversion\n",
    "train_len = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Advanced Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new feature columns\n",
    "trip_fare = []\n",
    "trip_duration = []\n",
    "trip_distance = []\n",
    "\n",
    "distance_to_duration = []\n",
    "fare_to_duration = []\n",
    "fare_to_distance = []\n",
    "waiting_fare_to_waiting_duration = []\n",
    "\n",
    "duration_from_time = []\n",
    "duration_error = []\n",
    "\n",
    "## j48 rules\n",
    "duration_bucket = []    ## 50\n",
    "fare_bucket = []        ## 50\n",
    "\n",
    "## dataset inspection rules\n",
    "fare_waiting_gap = []\n",
    "additional_fare_greater_than_250 = []\n",
    "is_duration_zero = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each row in the dataset\n",
    "for row in dataset.itertuples():\n",
    "    fare = float(row.fare)\n",
    "    additional_fare = float(row.additional_fare)\n",
    "    meter_waiting_fare = float(row.meter_waiting_fare)\n",
    "    \n",
    "    meter_waiting = row.meter_waiting\n",
    "    meter_waiting_till_pickup = row.meter_waiting_till_pickup\n",
    "    duration = row.duration\n",
    "    \n",
    "    pick_lat = row.pick_lat\n",
    "    pick_lon = row.pick_lon\n",
    "    drop_lat = row.drop_lat\n",
    "    drop_lon = row.drop_lon\n",
    "    \n",
    "    pickup_time = row.pickup_time.replace('\\'', '')\n",
    "    drop_time = row.drop_time.replace('\\'', '')\n",
    "    pickup_time = pickup_time.split('/')\n",
    "    drop_time = drop_time.split('/')\n",
    "    \n",
    "    # fare bucket\n",
    "    fare_bucket.append(int(math.ceil(fare / 50)))\n",
    "    \n",
    "    # total fare for the trip\n",
    "    cur_trip_fare = fare - (additional_fare + meter_waiting_fare)\n",
    "    trip_fare.append(cur_trip_fare)\n",
    "    \n",
    "    # trip duration\n",
    "    cur_trip_duration = duration - meter_waiting - meter_waiting_till_pickup\n",
    "    trip_duration.append(cur_trip_duration)\n",
    "    duration_bucket.append(int(math.ceil(cur_trip_duration / 50)))\n",
    "    \n",
    "    if(duration != 0):\n",
    "        is_duration_zero.append(0)\n",
    "    else:\n",
    "        is_duration_zero.append(1)\n",
    "    \n",
    "    # trip distance\n",
    "    cur_trip_distance = float(great_circle((drop_lat, drop_lon),(pick_lat, pick_lon)).kilometers)\n",
    "    trip_distance.append(cur_trip_distance)\n",
    "    \n",
    "    # trip distance to duration\n",
    "    try:\n",
    "        cur_dist_to_dur = cur_trip_distance / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_dist_to_dur  = 0\n",
    "    distance_to_duration.append(cur_dist_to_dur)\n",
    "    \n",
    "    # trip fare to trip duration\n",
    "    try:\n",
    "        cur_fare_to_duration = cur_trip_fare / cur_trip_duration\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_duration  = 0\n",
    "    fare_to_duration.append(cur_fare_to_duration)\n",
    "    \n",
    "    # trip fare to trip distance\n",
    "    try:\n",
    "        cur_fare_to_distance = cur_trip_fare / cur_trip_distance\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_to_distance  = 0\n",
    "    fare_to_distance.append(cur_fare_to_distance)\n",
    "    \n",
    "    # trip waiting fare to waiting duration\n",
    "    try:\n",
    "        cur_waiting_fare_to_waiting_dur = meter_waiting_fare / meter_waiting\n",
    "    except ZeroDivisionError:\n",
    "        cur_waiting_fare_to_waiting_dur  = 0\n",
    "    waiting_fare_to_waiting_duration.append(cur_waiting_fare_to_waiting_dur)\n",
    "    \n",
    "    # trip fare to waiting fare\n",
    "    try:\n",
    "        cur_fare_waiting_gap = (fare - meter_waiting_fare) / fare\n",
    "    except ZeroDivisionError:\n",
    "        cur_fare_waiting_gap  = 0\n",
    "    fare_waiting_gap.append(cur_fare_waiting_gap)\n",
    "    \n",
    "    # additional fare greater than 250\n",
    "    if(additional_fare > 250):\n",
    "        additional_fare_greater_than_250.append(1)\n",
    "    else:\n",
    "        additional_fare_greater_than_250.append(0)\n",
    "    \n",
    "    # time duration\n",
    "    # pickup time\n",
    "    month, day, y_hm = int(pickup_time[0]), int(pickup_time[1]), pickup_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    pickup_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # drop time\n",
    "    month, day, y_hm = int(drop_time[0]), int(drop_time[1]), drop_time[2].split(' ')\n",
    "    year, h_m = int(y_hm[0]), y_hm[1].split(':')\n",
    "    hour, minute = int(h_m[0]), int(h_m[1])\n",
    "    drop_time = datetime.datetime(year, month, day, hour, minute)\n",
    "    \n",
    "    # duration\n",
    "    cur_duration_from_time = (drop_time - pickup_time).seconds\n",
    "    duration_from_time.append(cur_duration_from_time)\n",
    "    duration_error.append(cur_duration_from_time - duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append new columns to dataset\n",
    "dataset['trip_fare'] = trip_fare\n",
    "dataset['trip_duration'] = trip_duration\n",
    "dataset['trip_distance'] = trip_distance\n",
    "dataset['distance_to_duration'] = distance_to_duration\n",
    "dataset['fare_to_duration'] = fare_to_duration\n",
    "dataset['fare_to_distance'] = fare_to_distance\n",
    "dataset['waiting_fare_to_waiting_duration'] = waiting_fare_to_waiting_duration\n",
    "dataset['duration_from_time'] = duration_from_time\n",
    "dataset['duration_error'] = duration_error\n",
    "dataset['duration_bucket'] = duration_bucket\n",
    "dataset['fare_bucket'] = fare_bucket\n",
    "\n",
    "dataset['fare_waiting_gap'] = fare_waiting_gap\n",
    "dataset['additional_fare_greater_than_250'] = additional_fare_greater_than_250\n",
    "dataset['is_duration_zero'] = is_duration_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column average values\n",
    "avg_fare = dataset['fare'].mean()\n",
    "avg_trip_fare = dataset['trip_fare'].mean()\n",
    "avg_waiting_fare = dataset['meter_waiting_fare'].mean()\n",
    "avg_fare_to_distance = dataset['fare_to_distance'].mean()\n",
    "avg_waiting_fare_to_duration = dataset['waiting_fare_to_waiting_duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new columns\n",
    "is_invalid_total_fare = []\n",
    "div_from_avg_total_fare = []\n",
    "div_from_avg_waiting_fare = []\n",
    "div_from_avg_waiting_fare_to_waiting_duration = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through each row in the dataset\n",
    "for row in dataset.itertuples():\n",
    "    fare = float(row.fare)\n",
    "    trip_fare = float(row.trip_fare)\n",
    "    meter_waiting_fare = float(row.meter_waiting_fare)\n",
    "    additional_fare = float(row.additional_fare)\n",
    "    \n",
    "    fare_to_distance = float(row.fare_to_distance)\n",
    "    waiting_fare_to_waiting_duration = float(row.waiting_fare_to_waiting_duration)\n",
    "    \n",
    "    # total fare less than or equal to zero\n",
    "    if(fare-meter_waiting_fare-additional_fare <= 0):\n",
    "        is_invalid_total_fare.append(1)\n",
    "    else:\n",
    "        is_invalid_total_fare.append(0)\n",
    "        \n",
    "    # diviation from average\n",
    "    div_from_avg_total_fare.append(fare - avg_fare)\n",
    "    div_from_avg_waiting_fare.append(meter_waiting_fare - avg_waiting_fare)\n",
    "    div_from_avg_waiting_fare_to_waiting_duration.append(waiting_fare_to_waiting_duration - avg_waiting_fare_to_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append new columns to dataset\n",
    "dataset['is_invalid_total_fare'] = is_invalid_total_fare\n",
    "dataset['div_from_avg_total_fare'] = div_from_avg_total_fare\n",
    "dataset['div_from_avg_waiting_fare'] = div_from_avg_waiting_fare\n",
    "dataset['div_from_avg_waiting_fare_to_waiting_duration'] = div_from_avg_waiting_fare_to_waiting_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling values into 0-1 range\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "features = [\n",
    "    'additional_fare',\n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup',\n",
    "    'pick_lat',\n",
    "    'pick_lon',\n",
    "    'drop_lat',\n",
    "    'drop_lon',\n",
    "    'fare',\n",
    "    'trip_fare',\n",
    "    'trip_duration',\n",
    "    'trip_distance',\n",
    "    'distance_to_duration',\n",
    "    'fare_to_duration',\n",
    "    'fare_to_distance',\n",
    "    'waiting_fare_to_waiting_duration', \n",
    "    'duration_from_time',\n",
    "    'duration_error',\n",
    "    'duration_bucket',\n",
    "    'fare_bucket'\n",
    "]\n",
    "\n",
    "dataset[features] = scaler.fit_transform(dataset[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into training and testing again\n",
    "\n",
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "test.drop(labels=['label'], axis=1, inplace=True)\n",
    "\n",
    "train['label'] = train['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time'\n",
    "]\n",
    "\n",
    "train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train['label']\n",
    "# X = train.drop(labels=['label'], axis=1)\n",
    "\n",
    "# # apply SelectKBest class to extract top 20 best features\n",
    "# bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "# fit = bestfeatures.fit(X, y)\n",
    "# dfscores = pd.DataFrame(fit.scores_)\n",
    "# dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# # concat two dataframes for better visualization\n",
    "# featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "# featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
    "# print(featureScores.nlargest(40, 'Score'))  #print 40 best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop less important columns\n",
    "labels_to_drop = [\n",
    "#     'trip_distance',\n",
    "#     'fare_to_duration',\n",
    "#     'trip_duration',\n",
    "#     'distance_to_duration',\n",
    "#     'duration_error',\n",
    "#     'meter_waiting_till_pickup',\n",
    "#     'additional_fare'\n",
    "]\n",
    "\n",
    "# train.drop(labels=labels_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Testing Different Algorithms</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperate train features and label\n",
    "\n",
    "y_train = train['label']\n",
    "X_train = train.drop(labels='label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValerrors</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953099</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959426</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>DecisionTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959680</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.975730</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.975690</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.974722</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.942613</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>MultipleLayerPerceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.954475</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>KNeighboors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.953249</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.955194</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CrossValMeans  CrossValerrors                   Algorithm\n",
       "0        0.953099        0.000741                         SVC\n",
       "1        0.959426        0.002853                DecisionTree\n",
       "2        0.959680        0.003705                    AdaBoost\n",
       "3        0.975730        0.002084                RandomForest\n",
       "4        0.975690        0.001869                  ExtraTrees\n",
       "5        0.974722        0.001197            GradientBoosting\n",
       "6        0.942613        0.019327     MultipleLayerPerceptron\n",
       "7        0.954475        0.000988                 KNeighboors\n",
       "8        0.953249        0.000375          LogisticRegression\n",
       "9        0.955194        0.000641  LinearDiscriminantAnalysis\n",
       "10       0.973298        0.001751               XGBClassifier"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test different algorithms\n",
    "random_state = 42\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(XGBClassifier(random_state=random_state, learning_rate=0.01))\n",
    "\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers:\n",
    "    cv_results.append(\n",
    "        cross_val_score(classifier, X_train, y=y_train, scoring=\"f1\", cv=kfold, n_jobs=4)\n",
    "    )\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\",\"XGBClassifier\"]})\n",
    "\n",
    "cv_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Handle Class Imbalancy</h2>\n",
    "<h3>Apply SMOTE to Generate Synthetic Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1402, 1: 13925}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "y_train_dict_value_count = {k:v for (k,v) in zip(unique, count)}\n",
    "y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=42)\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, count = np.unique(y_train, return_counts=True)\n",
    "# y_train_dict_value_count = {k:v for (k,v) in zip(unique, count)}\n",
    "# y_train_dict_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apply Class Weights to Handle Imbalanced Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.46611983, 0.55034111])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = {'class_weight': [{0:x, 1: 1.0-x} for x in weights]},\n",
    "    scoring = 'f1',\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "print('Best Parameters: ', grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc2bb619550>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out = pd.DataFrame({'score': grid_result.cv_results_['mean_test_score'], 'weight': weights})\n",
    "\n",
    "data_out.plot(x='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972896</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973058</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973236</td>\n",
       "      <td>0.144737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973166</td>\n",
       "      <td>0.192105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.239474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.972929</td>\n",
       "      <td>0.286842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973547</td>\n",
       "      <td>0.334211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973689</td>\n",
       "      <td>0.381579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973753</td>\n",
       "      <td>0.428947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.973464</td>\n",
       "      <td>0.476316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973634</td>\n",
       "      <td>0.523684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973870</td>\n",
       "      <td>0.571053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.973489</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.665789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.973439</td>\n",
       "      <td>0.713158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.760526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973497</td>\n",
       "      <td>0.807895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.972875</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.902632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.972246</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score    weight\n",
       "0   0.972896  0.050000\n",
       "1   0.973058  0.097368\n",
       "2   0.973236  0.144737\n",
       "3   0.973166  0.192105\n",
       "4   0.973051  0.239474\n",
       "5   0.972929  0.286842\n",
       "6   0.973547  0.334211\n",
       "7   0.973689  0.381579\n",
       "8   0.973753  0.428947\n",
       "9   0.973464  0.476316\n",
       "10  0.973634  0.523684\n",
       "11  0.973870  0.571053\n",
       "12  0.973489  0.618421\n",
       "13  0.972789  0.665789\n",
       "14  0.973439  0.713158\n",
       "15  0.973485  0.760526\n",
       "16  0.973497  0.807895\n",
       "17  0.972875  0.855263\n",
       "18  0.972977  0.902632\n",
       "19  0.972246  0.950000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = grid_result.best_params_\n",
    "# class_weights\n",
    "\n",
    "class_weights = {'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263}}\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross Validation for the Selected Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': {0: 0.5710526315789474, 1: 0.42894736842105263},\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "\n",
    "# number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "\n",
    "model_random = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=kfold, verbose=2, random_state=42, n_jobs=-1, scoring='f1')\n",
    "model_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Best parameters\n",
    "model_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GridSearch on best range\n",
    "param_grid = {\n",
    "    'n_estimators': [700, 800, 900],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [10, 12],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 33.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight={0: 0.5710526315789474,\n",
       "                                                            1: 0.42894736842105263},\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              m...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [20, 30],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [10, 12],\n",
       "                         'n_estimators': [700, 800, 900]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(**class_weights)\n",
    "\n",
    "model_grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, verbose=2, n_jobs=-1, scoring='f1')\n",
    "model_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 900}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train for the Selected Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Accuracy : 97.6329\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    max_depth=30,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    n_estimators=1800,\n",
    "    **class_weights\n",
    ")\n",
    "\n",
    "rfc_scores = []\n",
    "score = cross_val_score(model, X_train, y_train, cv=kfold, scoring='f1')\n",
    "rfc_scores.append(score.mean())\n",
    "\n",
    "print('% Accuracy :', round(score.mean()*100, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.5710526315789474,\n",
       "                                     1: 0.42894736842105263},\n",
       "                       criterion='gini', max_depth=30, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=12,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1800,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting and Preparing the Submission</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "trip_ids = test.tripid\n",
    "\n",
    "labels_to_drop = [\n",
    "    'tripid',\n",
    "#     'pick_lat',\n",
    "#     'pick_lon',\n",
    "#     'drop_lat',\n",
    "#     'drop_lon',\n",
    "    'pickup_time',\n",
    "    'drop_time',\n",
    "#     'trip_distance',\n",
    "#     'fare_to_duration',\n",
    "#     'trip_duration',\n",
    "#     'distance_to_duration',\n",
    "#     'duration_error',\n",
    "#     'meter_waiting_till_pickup',\n",
    "#     'additional_fare'\n",
    "]\n",
    "\n",
    "test = test.drop(labels=labels_to_drop, axis=1)\n",
    "\n",
    "predictions = model.predict(test)\n",
    "\n",
    "output = pd.DataFrame({'tripid': trip_ids, 'prediction': predictions})\n",
    "output.to_csv('../../submissions/160253h_submission_14.csv', index=False)\n",
    "print('Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training.\n",
    "\n",
    "KNNImputer to impute missing values.\n",
    "\n",
    "~with cross validation (to tune hiper-parameters).~ [not tuned]\n",
    "\n",
    "with feature engineering (added 16 new features).\n",
    "\n",
    "datetime columns have dropped (new features added).\n",
    "\n",
    "[model: Random Forest Classifier]\n",
    "\n",
    "\n",
    "file: 160253h_submission_13.csv,  score: 0.97883\n",
    "\n",
    "file: 160253h_submission_14.csv,  score: 0.97931   (with 3 more new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
